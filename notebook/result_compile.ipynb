{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27befdb8-7e05-49a0-bd4f-b7419a815a3f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59bf2491-958f-487c-8d5f-34ab60d6360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New current directory: /home/fiftyfour/Documents/NetworkPricingGraphContraction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "new_current_dir = os.getcwd()  # get new current working directory\n",
    "print(\"New current directory:\", new_current_dir)\n",
    "sys.path.append('./src/python/')\n",
    "\n",
    "# # import\n",
    "from preamble.preamble import *\n",
    "# from gamma.gamma import GammaNPP\n",
    "# from gamma.rules import make_rules, Rules, readable_rules\n",
    "# from gamma.common import npp_from_json, set_of_frozenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6698fece-bd7d-4648-b5cb-ce68fcc86580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import original problem results \n",
    "result_path = '/home/fiftyfour/Documents/Archive/experience_6/20241114_process_result/'\n",
    "with open(os.path.join(result_path, 'result_original.pkl'), 'rb') as f:\n",
    "    original_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289d765-31c4-4290-8143-64e002e61eff",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631ecef2-b83c-4217-a553-411bda900c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edge', 'obj_value', 'preprocess_time', 'solve_time', 'n_vertex', 'n_edge', 'n_tolled', 'finish', 'n', 'min_sl', 'max_sl', 'm', 'H1', 'H2', 'H3', 'H4', 'max_attemp', 'option', 'heuristic', 'cf1', 'cf2', 'cf3', 'cf4', 'cf5', 'cf6', 'cf7', 'cf8', 'cf9']\n"
     ]
    }
   ],
   "source": [
    "# create dataframe from original problem results\n",
    "cols_header = list(original_result['g30-01'].keys())\n",
    "print(cols_header)\n",
    "cols_header.remove('edge')\n",
    "rows_header = list(original_result.keys())\n",
    "\n",
    "original_meta_data = [\n",
    "                [r[k] for k in cols_header] for r in original_result.values()\n",
    "            ]\n",
    "original_meta_data = pd.DataFrame(original_meta_data, index=rows_header,columns=cols_header)\n",
    "original_meta_data['finish'] = original_meta_data['finish'].astype(bool)\n",
    "original_meta_data['finish'] = original_meta_data['finish'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741ee8a0-8ac1-4422-9d62-8ce3b76db07c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# the list of original problem name\n",
    "pb_list = [\n",
    "            'g45-03', 'g45-04', 'g30-08', 'g35-03', 'g30-10', 'g50-08', 'g45-10', 'g30-03', 'g45-02',\n",
    "            'g35-07', 'g35-05', 'g50-02', 'g40-05', 'g35-06', 'g50-06', 'g30-02', 'g45-09', 'g35-09',\n",
    "            'g50-10', 'g45-07', 'g40-10', 'g50-07', 'g40-01', 'g35-02', 'g35-04', 'g45-01', 'g45-05', 'g30-04',\n",
    "            'g45-08', 'g50-03', 'g30-05', 'g40-08', 'g30-01', 'g40-03', 'g40-04', 'g40-02', 'g35-10',\n",
    "            'g30-06', 'g50-01', 'g35-08', 'g35-01', 'g30-09', 'g40-09', 'g40-07', 'g50-05', 'g50-04', 'g40-06',\n",
    "            'g50-09', 'g30-07', 'g45-06',\n",
    "]\n",
    "    \n",
    "    \n",
    "result_dict = {}\n",
    "for problem_name in pb_list:\n",
    "    o_idx = f'000000-000000-000000-000000-0-0-0-0-0-0-0-0-0-{problem_name}'\n",
    "    result = {}\n",
    "    with open(os.path.join(result_path, f'result_{problem_name}.pkl'), 'rb') as f:\n",
    "        result[o_idx] = original_result[problem_name]\n",
    "        result.update(pickle.load(f))\n",
    "        \n",
    "    rows_header = list(map(lambda x: x[0], result[o_idx]['edge']))\n",
    "    cols_header = list(result.keys())\n",
    "    edge_index_data = [      \n",
    "                        [ r['edge'][i][1] for r in result.values() ] \n",
    "                        for i,_ in enumerate(rows_header)   \n",
    "                    ]\n",
    "    edge_value_data = [      \n",
    "                        [ r['edge'][i][2] for r in result.values() ] \n",
    "                        for i,_ in enumerate(rows_header)   \n",
    "                    ]\n",
    "    \n",
    "    flow_value_data = [      \n",
    "                        [ r['edge'][i][3] for r in result.values() ] \n",
    "                        for i,_ in enumerate(rows_header)   \n",
    "                    ]\n",
    "    # Table of the form\n",
    "    #  edge v1 v2 v3 v4 ....\n",
    "    #   e1  o11\n",
    "    #   e2  o21\n",
    "    #   e3  ...\n",
    "    # ....\n",
    "    edge_index_df = pd.DataFrame(edge_index_data, index = rows_header, columns=cols_header)\n",
    "    edge_value_df = pd.DataFrame(edge_value_data, index = rows_header, columns=cols_header)\n",
    "    flow_value_df = pd.DataFrame(flow_value_data, index = rows_header, columns=cols_header)\n",
    "    \n",
    "    \n",
    "    ## meta_data\n",
    "    # df of the form\n",
    "    #  pb v1 v2 v3 v4 ....\n",
    "    #   p1  o11\n",
    "    #   p2  o21\n",
    "    #   p3  ...\n",
    "    # ....\n",
    "    cols_header = list(result[o_idx].keys())\n",
    "    cols_header.remove('edge')\n",
    "    rows_header = list(result.keys())\n",
    "    \n",
    "    meta_data = [\n",
    "                    [r[k] for k in cols_header] for r in result.values()\n",
    "                ]\n",
    "    meta_data_df = pd.DataFrame(meta_data, index=rows_header,columns=cols_header)\n",
    "    meta_data_df[['min_sl', 'max_sl', 'm', 'H4']] = meta_data_df[['min_sl', 'max_sl', 'm', 'H4']].astype(int)\n",
    "    meta_data_df['finish'] = meta_data_df['finish'].astype(bool)\n",
    "    meta_data_df['finish'] = meta_data_df['finish'].astype(int)\n",
    "\n",
    "    # original problem objective, adjusted time, #tolled arcs, #vertex\n",
    "    o_obj      = meta_data_df['obj_value'][o_idx]\n",
    "    o_time     = meta_data_df['solve_time'][o_idx] + meta_data_df['preprocess_time'][o_idx]\n",
    "    o_n_tolled = meta_data_df['n_tolled'][o_idx]\n",
    "    o_n_vertex = meta_data_df['n_vertex'][o_idx]\n",
    "\n",
    "    meta_data_df['optimal_gap']    = (o_obj - meta_data_df['obj_value'])/abs(o_obj)\n",
    "    meta_data_df['absolute_error'] = abs(meta_data_df['obj_value'] - o_obj)\n",
    "    meta_data_df['relative_error'] = (meta_data_df['obj_value'] - o_obj)/o_obj\n",
    "    \n",
    "    meta_data_df['adjusted_time']   = meta_data_df['solve_time'] + meta_data_df['preprocess_time']\n",
    "    meta_data_df['time_increase']   = (meta_data_df['adjusted_time'] - o_time)/o_time\n",
    "    meta_data_df['adjusted_time_2'] = meta_data_df['adjusted_time'] # copy for later\n",
    "\n",
    "    remove_rows = []\n",
    "    # add up the solve time in the contracted space to adjusted_time_2\n",
    "    for index, row in meta_data_df.iterrows():\n",
    "\n",
    "        if (index != o_idx) and (not '-x' in index) and (not 'bsl' in index):\n",
    "            oid = index[:-1] + 'x'\n",
    "            meta_data_df.loc[index, 'adjusted_time_2'] = row['adjusted_time'] + meta_data_df.loc[oid, 'adjusted_time']\n",
    "        \n",
    "        else:\n",
    "            if (not '-x' in index) and (not 'bsl' in index):\n",
    "                remove_rows.append(index)\n",
    "    \n",
    "    meta_data_df.drop(remove_rows, inplace=True)\n",
    "    \n",
    "    meta_data_df['adjusted_time_increase'] = (meta_data_df['adjusted_time_2']-o_time)/o_time\n",
    "    meta_data_df['tolled_ratio']           = meta_data_df['n_tolled']/o_n_tolled\n",
    "    meta_data_df['vertex_ratio']           = meta_data_df['n_vertex']/o_n_vertex\n",
    "\n",
    "    # edge value\n",
    "    col1 = edge_value_df.iloc[0:,0]\n",
    "    col2 = edge_value_df.iloc[:, 1:].mean(axis=1)\n",
    "    \n",
    "    result = col2 - col1\n",
    "    meta_data_df['edge_diff_mean'] = result.mean() \n",
    "    meta_data_df['edge_diff_std']  = result.std()\n",
    "\n",
    "    # flow value\n",
    "    col1 = flow_value_df.iloc[0:,0]\n",
    "    col2 = flow_value_df.iloc[:, 1:].mean(axis=1)\n",
    "    \n",
    "    result = (col2 - col1)    \n",
    "    meta_data_df['flow_diff_mean'] = result.mean() \n",
    "    meta_data_df['flow_diff_std']  = result.std()\n",
    "    \n",
    "    # option was later renamed : method\n",
    "    # heuristic was later renamed : strategy\n",
    "    columns = ['min_sl', 'max_sl', 'm', 'H4', 'option', 'heuristic']\n",
    "    \n",
    "    # class for label and plot \n",
    "    meta_data_df['Class'] = meta_data_df[columns[:-2:]].astype(str).apply('-'.join, axis=1) # min_sl-max_sl-m-H4\n",
    "    meta_data_df['Class1'] = meta_data_df[columns[-3:]].astype(str).apply('-'.join, axis=1) # H4-option-heuristic\n",
    "    meta_data_df['Class2'] = meta_data_df[columns].astype(str).apply('-'.join, axis=1)      # min_sl-max_sl-m-H4-option-heuristic\n",
    "    meta_data_df['Class3'] = meta_data_df['Class2'].astype(str) + f'-{problem_name}'        # min_sl-max_sl-m-H4-option-heuristic-pb_name\n",
    "    meta_data_df['Class4'] = meta_data_df[columns[-2::]].astype(str).apply('-'.join, axis=1) + f'-{problem_name}' # option-heuristic-pb_name\n",
    "    meta_data_df['pb_name'] = problem_name\n",
    "\n",
    "    # only meta_data_df is used, the rest is not saved\n",
    "    result_dict[problem_name] = {\n",
    "                                'edge_index_df':edge_index_df.copy(),\n",
    "                                'edge_value_df':edge_value_df.copy(),\n",
    "                                'flow_value_df':flow_value_df.copy(),\n",
    "                                'meta_data_df':meta_data_df.copy()\n",
    "    }\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "for pb_name in result_dict:\n",
    "    merged_df = pd.concat([merged_df, result_dict[pb_name]['meta_data_df']])\n",
    "    \n",
    "merged_df = merged_df.T.filter(regex=r'^(?!000000-000000-000000-000000-0-0-0-0-0-0-0-0-0-.*).*$').T\n",
    "result_dict['combined'] = {\n",
    "                                'edge_index_df':None,\n",
    "                                'edge_value_df':None,\n",
    "                                'flow_value_df':None,\n",
    "                                'meta_data_df':merged_df.copy()\n",
    "    }\n",
    "# Export data\n",
    "with open('compile_data.pkl', 'wb') as f:\n",
    "    pickle.dump(result_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c77084e-5921-4041-9c08-9ba99d2802d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./compile_data.pkl', 'rb') as f:\n",
    "    RESULTS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45f5fe-d890-41b8-a3df-4ccad41ada6a",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b35aed-c852-42d3-bcce-7d8b75df73d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Plot settings\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = RESULTS['combined']['meta_data_df']\n",
    "\n",
    "\n",
    "### Color classes\n",
    "color_map = 'Accent'\n",
    "\n",
    "\n",
    "### Class\n",
    "class_labels = df['Class'].unique()\n",
    "cmap = plt.colormaps[color_map]  # Use the 'viridis' colormap\n",
    "n_colors = len(class_labels)\n",
    "colors = [cmap(i/n_colors) for i in range(n_colors)]\n",
    "class_color_map = dict(zip(class_labels, colors))\n",
    "\n",
    "### Option\n",
    "option_labels = df['option'].unique()\n",
    "cmap = plt.colormaps[color_map]  # Use the 'viridis' colormap\n",
    "n_colors = len(option_labels)\n",
    "colors = [cmap(i/n_colors) for i in range(n_colors)]\n",
    "option_color_map = dict(zip(option_labels, colors))\n",
    "\n",
    "### Heuristic\n",
    "heuristic_labels = df['heuristic'].unique()\n",
    "cmap = plt.colormaps[color_map]  # Use the 'viridis' colormap\n",
    "n_colors = len(heuristic_labels)\n",
    "colors = [cmap(i/n_colors) for i in range(n_colors)]\n",
    "heuristic_color_map = dict(zip(heuristic_labels, colors))\n",
    "\n",
    "### Problem\n",
    "problem_labels = df['pb_name'].unique()\n",
    "cmap = plt.colormaps[color_map]  # Use the 'viridis' colormap\n",
    "n_colors = len(problem_labels)\n",
    "colors = [cmap(i/n_colors) for i in range(n_colors)]\n",
    "problem_color_map = dict(zip(problem_labels, colors))\n",
    "\n",
    "fr_dict = {\n",
    "    'optimal_gap' : \"Écart d'optimalité relatif\",\n",
    "    'heuristic': \"Heuristique de rétrorésolution\",\n",
    "    'option': \"Heuristique de transformation\",\n",
    "    'Class' : 'Classe',\n",
    "    'tolled_ratio' : \"Ratio d'arc controllé\",\n",
    "    'adjusted_time_increase' : \"Augmentation relative du temps de résolution total\",\n",
    "    'time_increase' : \"Augmentation relative du temps de résolution\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'backend': 'pdf',\n",
    "    #'axes.labelsize': 12,\n",
    "    # 'text.fontsize': 12,\n",
    "    # 'legend.fontsize': 12,\n",
    "    # 'xtick.labelsize': 10,\n",
    "    # 'ytick.labelsize': 10,\n",
    "    'text.usetex': True,\n",
    "    'axes.unicode_minus': True,\n",
    "    'font.family': 'serif',  # Use serif fonts\n",
    "    'font.serif': ['Computer Modern Roman'],  # Specify LaTeX serif font\n",
    "    'font.sans-serif': ['Computer Modern Sans Serif'],  # Optional\n",
    "    'font.monospace': ['Computer Modern Typewriter']  # Optional\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ad42c8-eb9d-45e6-b3b7-2b93836c202a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Quadrant plot (obsolete):\n",
    "### quadrant 1 : Parameter Distribution\n",
    "### quadrant 2 : Option Distribution\n",
    "### quadrant 3 : Heuristic Distribution\n",
    "### quadrant 4 : Problem Distribution ()\n",
    "\n",
    "\n",
    "### The purpose is to look for a tendency when the optimal ratio is high\n",
    "### Don't be fool by randomness\n",
    "### Every transformation for each problem was randomly generated\n",
    "\n",
    "if False:\n",
    "    title_font_size = 32\n",
    "    label_font_size = 24\n",
    "    \n",
    "    for h4 in [0, 1]:\n",
    "        for opt_r in [0.05, 0.10, 0.25, 0.50]:\n",
    "    \n",
    "            conditions = [\n",
    "                (df['m']!=0),                   # The number of equivalence classes \n",
    "                (df['max_sl']<=5),              # Maximum length one equivalence class can have\n",
    "                (df['max_sl']>=2),              # Maximum length one equivalence class can have (0 mean arbitrary, so whe need a lower limit)\n",
    "                (df['H4']==h4),                 # Contiguous hypothesis (1 or 0)\n",
    "                (df['min_sl']>=2),              # Minimum length one none trivial equivalence class can have\n",
    "                (df['heuristic']!='x'),         # Heuristic (1-2-3-4-5-x) (x is in the transformed space)\n",
    "                (df['max_sl']==df['min_sl']),\n",
    "            ]\n",
    "            \n",
    "            \n",
    "            data_df = df[np.logical_and.reduce(conditions)]\n",
    "            total_element = len(data_df)\n",
    "            \n",
    "            conditions.append(df['optimality_gap']<=opt_r)   # Optimal gap\n",
    "            \n",
    "            data_df = df[np.logical_and.reduce(conditions)]\n",
    "            number_of_element = len(data_df)\n",
    "            # print(f\"Optimal ratio :{opt_r}, H4:{h4}\")\n",
    "            # print(f\"Number of element\\t: {number_of_element}\")\n",
    "            # print(f\"Total number of element\\t: {total_element}\")\n",
    "            \n",
    "            # Create the subplots\n",
    "            fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(30, 10))\n",
    "            fig.subplots_adjust(left=0, right=0.95, bottom=0, top=1, wspace=0.015, hspace=0)\n",
    "            \n",
    "            \n",
    "            # Plot 1 - Parameter Distribution when optimal ratio is over x%\n",
    "            fracs = data_df['Class'].value_counts(normalize=True)\n",
    "            mask = fracs > 0.01\n",
    "            labels = fracs.index[mask].tolist()\n",
    "            sizes = fracs[mask].tolist()\n",
    "            \n",
    "            # Add a category for classes less than 0.01\n",
    "            mask_less_than_001 = fracs <= 0.01\n",
    "            if mask_less_than_001.any():\n",
    "                num_others = mask_less_than_001.sum()\n",
    "                class_color_map[f'Others ({num_others})'] = 'gray'\n",
    "                labels.append(f'Others ({num_others})')\n",
    "                sizes.append(fracs[mask_less_than_001].sum())\n",
    "            \n",
    "            colors = [class_color_map[label] for label in labels]\n",
    "            axs[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', textprops={'fontsize': label_font_size}, rotatelabels=True, pctdistance=0.85, labeldistance=1.05)\n",
    "            if h4==1:\n",
    "                axs[0].set_title(r'Paramètres (\\texttt{min_sl}-\\texttt{max_sl}-\\texttt{m}-$\\texttt{H}_4$)', fontsize=title_font_size, y=1.05)\n",
    "            ####################################################################\n",
    "            ####################################################################\n",
    "            \n",
    "            \n",
    "            # Plot 2 - Option Distribution when optimal ratio is over x%\n",
    "            fracs = data_df['option'].value_counts(normalize=True)\n",
    "            mask = fracs > 0.0005\n",
    "            labels = fracs.index[mask].tolist()\n",
    "            sizes = fracs[mask].tolist()\n",
    "            \n",
    "            # Add a category for options less than 0.0005\n",
    "            mask_less_than_0005 = fracs <= 0.0005\n",
    "            if mask_less_than_0005.any():\n",
    "                num_others = mask_less_than_0005.sum()\n",
    "                option_color_map[f'Others ({num_others})'] = 'gray'\n",
    "                labels.append(f'Others ({num_others})')\n",
    "                sizes.append(fracs[mask_less_than_0005].sum())\n",
    "            \n",
    "            colors = [option_color_map[label] for label in labels]\n",
    "            labels = [rf\"\\textbf{{{x}}}\" for x in labels]\n",
    "            axs[1].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', textprops={'fontsize': label_font_size}, rotatelabels=False, pctdistance=0.85, labeldistance=1.05)\n",
    "    \n",
    "            if h4==1:\n",
    "                axs[1].set_title('Heuristique de transformation', fontsize=title_font_size, y=1.05)\n",
    "            ####################################################################\n",
    "            ####################################################################\n",
    "            \n",
    "            \n",
    "            # Plot 3 - Heuristic Distribution when optimal ratio is over x%\n",
    "            fracs = data_df['heuristic'].value_counts(normalize=True)\n",
    "            mask = fracs > 0.01\n",
    "            labels = fracs.index[mask].tolist()\n",
    "            sizes = fracs[mask].tolist()\n",
    "            \n",
    "            # Add a category for heuristics less than 0.01\n",
    "            mask_less_than_001 = fracs <= 0.01\n",
    "            if mask_less_than_001.any():\n",
    "                num_others = mask_less_than_001.sum()\n",
    "                heuristic_color_map[f'Others ({num_others})'] = 'gray'\n",
    "                labels.append(f'Others ({num_others})')\n",
    "                sizes.append(fracs[mask_less_than_001].sum())\n",
    "            \n",
    "            colors = [heuristic_color_map[label] for label in labels]\n",
    "            axs[2].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', textprops={'fontsize': label_font_size}, rotatelabels=False, pctdistance=0.85, labeldistance=1.05)\n",
    "            if h4==1:\n",
    "                axs[2].set_title('Heuristique de rétrorésolution', fontsize=title_font_size, y=1.05)\n",
    "            ####################################################################\n",
    "            ####################################################################\n",
    "    \n",
    "            if False:\n",
    "                # Plot 4 - Problem Distribution when optimal ratio is over x%\n",
    "                fracs = data_df['pb_name'].value_counts(normalize=True)\n",
    "                mask = fracs > 0.01\n",
    "                labels = fracs.index[mask].tolist()\n",
    "                sizes = fracs[mask].tolist()\n",
    "                \n",
    "                # Add a category for problems less than 0.01\n",
    "                mask_less_than_001 = fracs <= 0.01\n",
    "                if mask_less_than_001.any():\n",
    "                    num_others = mask_less_than_001.sum()\n",
    "                    problem_color_map[f'Others ({num_others})'] = 'gray'\n",
    "                    labels.append(f'Others ({num_others})')\n",
    "                    sizes.append(fracs[mask_less_than_001].sum())\n",
    "            \n",
    "                colors = [problem_color_map[label] for label in labels]\n",
    "                axs[3].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', textprops={'fontsize': label_font_size}, rotatelabels=True, pctdistance=0.85, labeldistance=1.05)\n",
    "                axs[3].set_title('Problem Distribution', fontsize=title_font_size, y=1.05)\n",
    "            ####################################################################\n",
    "            ####################################################################\n",
    "            \n",
    "            # plt.tight_layout()\n",
    "            plt.savefig(f'./result/quadrant_{int(round(opt_r*100,0))}_{h4}_{number_of_element}_{total_element}.pdf', bbox_inches='tight')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14251b95-272e-4b2a-9aba-47dc92bbc1c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_11164/3159984605.py:66: UserWarning: FigureCanvasPdf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "### Pairplot (obsolete)\n",
    "if False:\n",
    "    title_font_size = 32\n",
    "    label_font_size = 24\n",
    "    \n",
    "    for opt_r in [0.99]: #0.05, 0.10, 0.25, 0.50]:\n",
    "        for option in [\"rnd\", \"min\", \"avg\", \"max\", \"bsl\"]:\n",
    "            for h4 in [1, 0]:\n",
    "                conditions = [\n",
    "                    (df['m']!=0),                   # The number of equivalence classes \n",
    "                    (df['max_sl']<=5),              # Maximum length one equivalence class can have\n",
    "                    (df['max_sl']>=2),              # Maximum length one equivalence class can have (0 mean arbitrary, so whe need a lower limit)\n",
    "                    (df['H4']==h4),                 # Contiguous hypothesis (1 or 0)\n",
    "                    (df['min_sl']>=2),              # Minimum length one none trivial equivalence class can have\n",
    "                    (df['heuristic']!='x'),         # Heuristic (1-2-3-4-5-x) (x is in the transformed space)\n",
    "                    (df['max_sl']==df['min_sl']),\n",
    "                    (df['option']==option),         # Option when going back to the original problem\n",
    "                ]\n",
    "                \n",
    "        \n",
    "                conditions.append(df['optimality_gap']<=opt_r)   # Optimal ratio\n",
    "                data_df = df[np.logical_and.reduce(conditions)]\n",
    "                total_element = len(data_df)\n",
    "                \n",
    "                \n",
    "                data_df = df[np.logical_and.reduce(conditions)]\n",
    "                number_of_element = len(data_df)\n",
    "                \n",
    "                if number_of_element>=25:\n",
    "           \n",
    "                    # # Create a PairGrid\n",
    "                    # pair_grid = sns.PairGrid(data_df, hue='Class')\n",
    "                    \n",
    "                    # # Map upper triangle with regplot\n",
    "                    # pair_grid.map_upper(sns.regplot, scatter_kws={'s': 5})\n",
    "                    \n",
    "                    # # Map lower triangle with kdeplot\n",
    "                    # pair_grid.map_lower(sns.kdeplot)\n",
    "                    \n",
    "                    # # Map diagonal with histplot\n",
    "                    # pair_grid.map_diag(sns.histplot, kde=True)\n",
    "                    \n",
    "                    # # Add legend\n",
    "                    # pair_grid.add_legend()\n",
    "    \n",
    "                    # Get unique classes and sort them\n",
    "                    sorted_classes = sorted(data_df['Class'].unique())\n",
    "                    pairplot = sns.pairplot(data_df,\n",
    "                                vars=['optimality_gap', 'tolled_ratio', 'adjusted_time_increase'],\n",
    "                                hue='Class',\n",
    "                                hue_order = sorted_classes,\n",
    "                                diag_kind='kde',\n",
    "                                plot_kws=dict(s=5), # Set the size of the points to 5,\n",
    "                                 # corner=True\n",
    "                                 )\n",
    "    \n",
    "                    \n",
    "                    # Set custom labels for each axis\n",
    "                    for ax in pairplot.axes.flatten():\n",
    "                        # Set x and y labels using the desired format\n",
    "                        # ax.set_xlabel(ax.get_xlabel().replace(\"_\", \" \").title(), fontsize=10)\n",
    "                        # ax.set_ylabel(ax.get_ylabel().replace(\"_\", \" \").title(), fontsize=10)\n",
    "    \n",
    "                        if ax.get_xlabel():\n",
    "                            ax.set_xlabel(fr_dict[ax.get_xlabel()], fontsize=10)\n",
    "                        if ax.get_ylabel():\n",
    "                            ax.set_ylabel(fr_dict[ax.get_ylabel()], fontsize=10)\n",
    "                    \n",
    "                    # plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    plt.savefig(f'./result/pairplot_{int(round(opt_r*100,0))}-{option}-{h4}-{number_of_element}_{total_element}.pdf', bbox_inches='tight')\n",
    "                    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07089adf-bfa6-4d96-9656-35043873f2d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/3582622266.py:71: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[j].set_xticklabels(xticklabels,  rotation=45,ha='center', va='center')\n",
      "/tmp/ipykernel_7051/3582622266.py:71: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[j].set_xticklabels(xticklabels,  rotation=45,ha='center', va='center')\n",
      "/tmp/ipykernel_7051/3582622266.py:71: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax[j].set_xticklabels(xticklabels,  rotation=45,ha='center', va='center')\n"
     ]
    }
   ],
   "source": [
    "### Boxplot\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "##########################################  ##########################################\n",
    "# RND - Shortest path          (RND - 1) #  # ZIP - Shortest path          (ZIP - 1) #\n",
    "# RND - Lower bound            (RND - 2) #  # ZIP - Lower bound            (ZIP - 2) #\n",
    "# RND - Upper bound            (RND - 3) #  # ZIP - Upper bound            (ZIP - 3) #\n",
    "# RND - Adaptative lower bound (RND - 4) #  # ZIP - Adaptative lower bound (ZIP - 4) #\n",
    "# RND - Adaptative upper bound (RND - 5) #  # ZIP - Adaptative upper bound (ZIP - 5) #\n",
    "# RND - Comparative projection (RND - 6) #  # ZIP - Comparative projection (ZIP - 6) #\n",
    "##########################################  ##########################################\n",
    " \n",
    "##########################################  ##########################################\n",
    "# MIN - Shortest path          (MIN - 1) #  # AVG - Shortest path          (AVG - 1) #\n",
    "# MIN - Lower bound            (MIN - 2) #  # AVG - Lower bound            (AVG - 2) #\n",
    "# MIN - Upper bound            (MIN - 3) #  # AVG - Upper bound            (AVG - 3) #\n",
    "# MIN - Adaptative lower bound (MIN - 4) #  # AVG - Adaptative lower bound (AVG - 4) #\n",
    "# MIN - Adaptative upper bound (MIN - 5) #  # AVG - Adaptative upper bound (AVG - 5) #\n",
    "# MIN - Comparative projection (MIN - 6) #  # AVG - Comparative projection (AVG - 6) #\n",
    "##########################################  ##########################################\n",
    "\n",
    "##########################################  ##########################################\n",
    "# MAX - Shortest path          (MAX - 1) #  # BSL - Shortest path          (MAX - 1) #\n",
    "# MAX - Lower bound            (MAX - 2) #  # BSL - Lower bound            (MAX - 2) #\n",
    "# MAX - Upper bound            (MAX - 3) #  # BSL - Upper bound            (MAX - 3) #\n",
    "# MAX - Adaptative lower bound (MAX - 4) #  # BSL - Adaptative lower bound (MAX - 4) #\n",
    "# MAX - Adaptative upper bound (MAX - 5) #  # BSL - Adaptative upper bound (MAX - 5) #\n",
    "# MAX - Comparative projection (MAX - 6) #  #                                        #\n",
    "##########################################  ##########################################\n",
    "\n",
    "title_font_size   = 32\n",
    "legend_label_size = 22\n",
    "label_font_size   = 35\n",
    "tick_font_size    = 22\n",
    "\n",
    "hue_order = ['rnd','bsl','zip','min','avg','max']\n",
    "order = ['1','2','3','4','5','6','x']\n",
    "\n",
    "# xticklabels = [\n",
    "#                'Shortest path (1)',\n",
    "#                'Lower bound (2)', \n",
    "#                'Upper bound (3)', \n",
    "#                'Adapt. lower bound (4)', \n",
    "#                'Adapt. upper bound (5)', \n",
    "#                'Hybrid (6)', \n",
    "#                'Contracted space (x)'\n",
    "# ]\n",
    "\n",
    "xticklabels = [\n",
    "               'Plus court chemin (1)',\n",
    "               'Borne inférieure (2)', \n",
    "               'Borne supérieure (3)', \n",
    "               'Borne inférieure adapt. (4)', \n",
    "               'Borne supérieure adapt. (5)', \n",
    "               'Hybride (6)', \n",
    "               'Espace contracté (x)'\n",
    "]\n",
    "\n",
    "for yy in ['adjusted_time_increase', 'optimal_gap', 'time_increase']:\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 20))\n",
    "    for i in [1, 0]:\n",
    "        j = 0 if i==1 else 1\n",
    "        sns.boxplot(data=df[df['H4']==i], x=\"heuristic\", y=yy, hue=\"option\", hue_order=hue_order, order=order, ax=ax[j], legend=i).set(xlabel='')\n",
    "\n",
    "        ax[j].tick_params(which='major', width=1.0, length=30, axis='x', labelsize=tick_font_size)\n",
    "        if i==0:\n",
    "            ax[j].xaxis.set_ticks_position('top')  # Move x-ticks to the top\n",
    "            ax[j].set_xticklabels(xticklabels,  rotation=45,ha='center', va='center')\n",
    "            ax[j].tick_params(axis='x', pad=85)\n",
    "        else:\n",
    "            ax[j].set_xticklabels([])  # This removes the x-tick labels\n",
    "            \n",
    "        ax[j].tick_params(axis='y', labelsize=tick_font_size)  # Adjust the labelsize as needed\n",
    "        if 'time' in yy:\n",
    "            ax[j].axhline(y=0, color='red', linestyle='--')\n",
    "            ax[j].axhline(y=-0.25, color='red', linestyle='--')\n",
    "            ax[j].axhline(y=-0.5, color='red', linestyle='--')\n",
    "\n",
    "        else:\n",
    "            ax[j].axhline(y=0, color='red', linestyle='--')\n",
    "            ax[j].axhline(y=0.25, color='red', linestyle='--')\n",
    "            ax[j].axhline(y=0.5, color='red', linestyle='--')\n",
    "            \n",
    "        # ax[j].set_ylabel(fr_dict[yy], fontsize=label_font_size)\n",
    "        ax[j].set_ylabel('')\n",
    "        \n",
    "\n",
    "        # Adding a text box with rounded corners\n",
    "        textstr = f'$H_4={i}$'\n",
    "        props = dict(boxstyle='round', facecolor='lightblue', alpha=0.5)\n",
    "        \n",
    "        # Place the text box at a specified position\n",
    "        ax[j].text(0.015, 0.975, textstr, fontsize=legend_label_size, bbox=props, \n",
    "        ha='left', va='top', transform=ax[j].transAxes)  # Use axes coordinates\n",
    "\n",
    "        # Add the legend, including the phantom label\n",
    "        handles, labels = ax[j].get_legend_handles_labels()\n",
    "        bf_labels = [rf\"\\textbf{{{x}}}\" for x in labels]\n",
    "        if i==1:\n",
    "            ax[j].legend(handles=handles, labels=bf_labels, bbox_to_anchor=(0.5, 1.015), loc='lower center', ncol=len(hue_order) + 1, fontsize=legend_label_size)\n",
    "        \n",
    "        \n",
    "        # To set the x-axis range\n",
    "        if yy =='optimality_gap':\n",
    "            ax[j].set_ylim(-0.6, 1.3)\n",
    "            plt.ylim(ymin=-0.6, ymax=1.3)\n",
    "                \n",
    "        elif yy == 'adjusted_time_increase':\n",
    "            plt.ylim(ymin=-1.05, ymax=1.5)\n",
    "            ax[j].set_ylim(-1.05, 1.5)\n",
    "            \n",
    "        elif yy == 'time_increase':\n",
    "            plt.ylim(ymin=-1.05, ymax=0.5)\n",
    "            ax[j].set_ylim(-1.05, 0.5)\n",
    "            \n",
    "    fig.text(0.025, 0.5+0.05, fr_dict[yy], va='center', ha='center', rotation='vertical', fontsize=label_font_size)\n",
    "    fig.text(0.5+0.05, 0.025, \"Stratégies\", va='center', ha='center', fontsize=label_font_size)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.05)\n",
    "    plt.savefig(f'./result/boxplot_full_{yy}_H4.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d58d50-0281-488f-9d3f-64ef5ca1f5ed",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31015f1-e1c8-456e-9526-99764ef365b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2458685, 46)\n",
      "71484 71484\n",
      "71484 71484\n",
      "all transformation are unique\n",
      "all solve solve transformation are unique\n",
      "all generated transformation have been solved\n"
     ]
    }
   ],
   "source": [
    "## Retrieving every transformation parametrisation use\n",
    "import glob\n",
    "def convert(x):\n",
    "    idn1, idn2, idn3, n, min_sl, max_sl, m, H1, H2, H3, H4, max_attemp, pb_name1, pb_name2, *_ = x.split('-')\n",
    "    return '-'.join((idn1, idn2, idn3, n, min_sl, max_sl, m, H4, max_attemp, pb_name1+'-'+pb_name2))\n",
    "\n",
    "\n",
    "\n",
    "# List all directories in the specified folder\n",
    "data_directory = \"/home/fiftyfour/Documents/Archive/experience_6/full_data/home/hebjul/NetworkPricingGraphContraction/data/generated/problems/paper/\"\n",
    "subdirectories = [d for d in os.listdir(data_directory)]\n",
    "subdirectories.remove('original')\n",
    "\n",
    "# dictionary of probleme name and its transformation file \n",
    "problems_transformations = {pb_name: glob.glob(os.path.join(data_directory, pb_name, '*-P.pkl')) for pb_name in subdirectories}\n",
    "\n",
    "transformation_ids = []\n",
    "for (pb_name, files) in problems_transformations.items():\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            idn1, idn2 = os.path.splitext(os.path.basename(file))[0].split('-')[:2:]\n",
    "            # the unique id string to identify transformation where (idn1, idn2) is added for uniqueness\n",
    "            # (idn1, idn2), idn3, n, min_sl, max_sl, m, H1, H2, H3, H4, max_attemp, pb_name  \n",
    "            transformation_ids += list(map(lambda x: f'{idn1}-{idn2}-{x}', pickle.load(f).keys()))\n",
    "\n",
    "trans_ids_split = [x.split('-') for x in transformation_ids]\n",
    "all_trans_list = list(map(convert, transformation_ids))\n",
    "\n",
    "####\n",
    "success = RESULTS\n",
    "best_case_scenario_trans_list = success[(success['heuristic']=='1') & (success['option']=='bsl')].index.tolist()\n",
    "best_case_scenario_trans_list = list(map(convert, best_case_scenario_trans_list))\n",
    "\n",
    "\n",
    "## Verify uniqueness\n",
    "print(len(all_trans_list),len(set(all_trans_list)))\n",
    "print(len(best_case_scenario_trans_list),len(set(best_case_scenario_trans_list)))\n",
    "\n",
    "if len(all_trans_list) == len(set(all_trans_list)):\n",
    "    print('all transformation are unique')\n",
    "if len(best_case_scenario_trans_list) == len(set(best_case_scenario_trans_list)):\n",
    "    print('all solve solve transformation are unique')\n",
    "if len(set(all_trans_list)) == len(set(best_case_scenario_trans_list)):\n",
    "    print('all generated transformation have been solved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9771aa2f-b75f-47d8-a90c-57391b55407f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "\\texttt{min\\_sl} & \\texttt{max\\_sl} & \\texttt{m} & Total (\\(\\text{\\texttt{H}}_4 = 1\\)) & Total (\\(\\text{\\texttt{H}}_4 = 0\\)) \\\\\n",
      "\\midrule\n",
      "2 & 0 & 0 & 1670 & 14659 \\\\\n",
      "2 & 2 & 0 & 411 & 3502 \\\\\n",
      "2 & 2 & 1 & 101 & 1541 \\\\\n",
      "2 & 2 & 2 & 170 & 4273 \\\\\n",
      "2 & 2 & 3 & 158 & 4838 \\\\\n",
      "3 & 3 & 0 & 414 & 3331 \\\\\n",
      "3 & 3 & 1 & 101 & 1316 \\\\\n",
      "3 & 3 & 2 & 167 & 3912 \\\\\n",
      "3 & 3 & 3 & 161 & 4691 \\\\\n",
      "4 & 4 & 0 & 417 & 3131 \\\\\n",
      "4 & 4 & 1 & 101 & 1097 \\\\\n",
      "4 & 4 & 2 & 170 & 3646 \\\\\n",
      "4 & 4 & 3 & 161 & 4592 \\\\\n",
      "5 & 5 & 0 & 409 & 3081 \\\\\n",
      "5 & 5 & 1 & 101 & 968 \\\\\n",
      "5 & 5 & 2 & 170 & 3456 \\\\\n",
      "5 & 5 & 3 & 162 & 4406 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "5044 66440\n"
     ]
    }
   ],
   "source": [
    "### Parameters of the transformations used and their total number\n",
    "\n",
    "result = df.groupby(['min_sl', 'max_sl', 'm', 'H4', 'heuristic', 'option']).size().reset_index(name='count')\n",
    "\n",
    "filtered_df_1 = result[(result['heuristic']=='1') & (result['option']=='bsl') & (result['H4']==1)]\n",
    "total_sum_1 = filtered_df_1['count'].sum()\n",
    "\n",
    "filtered_df_0 = result[(result['heuristic']=='1') & (result['option']=='bsl') & (result['H4']==0)]\n",
    "total_sum_0 = filtered_df_0['count'].sum()\n",
    "\n",
    "# Create a DataFrame to export as LaTeX\n",
    "latex_table = pd.DataFrame({\n",
    "    '\\\\texttt{min\\\\_sl}': list(filtered_df_1['min_sl']),\n",
    "    '\\\\texttt{max\\\\_sl}': list(filtered_df_1['max_sl']),\n",
    "    '\\\\texttt{m}': list(filtered_df_1['m']),\n",
    "    'Total (\\\\(\\\\text{\\\\texttt{H}}_4 = 1\\\\))': list(filtered_df_1['count']),\n",
    "    'Total (\\\\(\\\\text{\\\\texttt{H}}_4 = 0\\\\))': list(filtered_df_0['count'])\n",
    "})\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_output = latex_table.to_latex(index=False)\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "print(latex_output)\n",
    "print(total_sum_1,total_sum_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f34e1bf-50bd-4459-b53e-d76803cd44c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " & Minimum & Médian & Variance & Moyenne & Maximum \\\\\n",
      "\\midrule\n",
      "Sommets & 38.00 & 54.00 & 9.10 & 54.04 & 59.00 \\\\\n",
      "Arcs contrôlés & 29.00 & 39.00 & 2.85 & 38.72 & 41.00 \\\\\n",
      "Arcs & 193.00 & 203.00 & 2.85 & 202.72 & 205.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " & Minimum & Médian & Variance & Moyenne & Maximum \\\\\n",
      "\\midrule\n",
      "Sommets & 56.00 & 58.00 & 0.43 & 58.29 & 59.00 \\\\\n",
      "Arcs contrôlés & 36.00 & 40.00 & 0.79 & 39.90 & 41.00 \\\\\n",
      "Arcs & 200.00 & 204.00 & 0.79 & 203.90 & 205.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Statistics on the topology of transformed graphs\n",
    "\n",
    "df = RESULTS\n",
    "df = df[(df['option']=='bsl') & (df['heuristic']=='1')]\n",
    "for h4 in [0, 1]:\n",
    "    results = {}\n",
    "    \n",
    "    for tt in ['n_vertex', 'n_tolled', 'n_edge']:\n",
    "        \n",
    "        # Filter the DataFrame for the specific 'H4' value\n",
    "        filtered_data = df[df['H4'] == h4][tt]\n",
    "        \n",
    "        # Calculate the required statistics\n",
    "        results[tt] = {\n",
    "            'Minimum': filtered_data.min(),\n",
    "            'Médian': filtered_data.median(),\n",
    "            'Variance':filtered_data.var(),\n",
    "            'Moyenne': filtered_data.mean(),\n",
    "            'Maximum': filtered_data.max()\n",
    "        }\n",
    "\n",
    "    # Create a new DataFrame from the results\n",
    "    result_df = pd.DataFrame(results).T  # Transpose to have columns as 'min', 'median', 'mean', 'max'\n",
    "    # result_df.index.name = 'Metrics'\n",
    "    result_df = result_df.rename(index={\n",
    "                                            'n_vertex': 'Sommets',\n",
    "                                            'n_tolled': 'Arcs contrôlés',\n",
    "                                            'n_edge': 'Arcs'\n",
    "                                        })\n",
    "\n",
    "    latex_table = result_df.to_latex(index=True, float_format=\"%.2f\")\n",
    "    print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9884e732-f996-4035-8c2c-cdf7635806dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      " & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "\\midrule\n",
      "1 & 59470 & 66440 & 44979 & 66374 & 58359 & 58414 & 354036 \\\\\n",
      "2 & 59447 & 66440 & 44996 & 66374 & 58360 & 58419 & 354036 \\\\\n",
      "3 & 66205 & 66440 & 64555 & 66385 & 66404 & 66379 & 396368 \\\\\n",
      "4 & 66167 & 66440 & 64575 & 66378 & 66411 & 66377 & 396348 \\\\\n",
      "5 & 66205 & 66440 & 64555 & 66385 & 66404 & 66379 & 396368 \\\\\n",
      "6 & 5340 & 0 & 10973 & 9247 & 9317 & 9430 & 44307 \\\\\n",
      "x & 66213 & 0 & 64582 & 66402 & 66427 & 66398 & 330022 \\\\\n",
      "Total & 389047 & 332200 & 359215 & 407545 & 391682 & 391796 & 2271485 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      " & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "\\midrule\n",
      "1 & 4497 & 5044 & 3510 & 5038 & 4471 & 4538 & 27098 \\\\\n",
      "2 & 4495 & 5044 & 3510 & 5038 & 4471 & 4538 & 27096 \\\\\n",
      "3 & 4811 & 5044 & 4900 & 5038 & 5020 & 5037 & 29850 \\\\\n",
      "4 & 4808 & 5044 & 4900 & 5038 & 5020 & 5037 & 29847 \\\\\n",
      "5 & 4811 & 5044 & 4900 & 5038 & 5020 & 5037 & 29850 \\\\\n",
      "6 & 2832 & 0 & 4034 & 3900 & 3917 & 3970 & 18653 \\\\\n",
      "x & 4811 & 0 & 4900 & 5038 & 5020 & 5037 & 24806 \\\\\n",
      "Total & 31065 & 25220 & 30654 & 34128 & 32939 & 33194 & 187200 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Number of instances solved by each combination of method and strategy for transformations constrained by H4\n",
    "for h4 in range(2):\n",
    "    dfs = []\n",
    "    for key in RESULTS:\n",
    "        if not key == 'combined':\n",
    "                \n",
    "            df = result_dict[key]['edge_value_df']\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "            column_names = df.columns.tolist()\n",
    "            data = [tuple(name.rsplit('-')[-6:]) for name in column_names]\n",
    "            data = filter(lambda x: x[0]==str(h4), data)\n",
    "         \n",
    "            data = ['-'.join(c[-2::]) for c in data]\n",
    "\n",
    "            unique_elements, counts = np.unique(data, return_counts=True)\n",
    "    \n",
    "            # Create a frequency dictionary\n",
    "            freq_dict = dict(zip(unique_elements, counts))\n",
    "            \n",
    "            # Initialize an empty DataFrame\n",
    "            methods = ['rnd', 'bsl',  'zip', 'min', 'avg', 'max']\n",
    "            instances = [1, 2, 3, 4, 5, 6, 'x']\n",
    "            table_data = {method: [freq_dict.get(f'{method}-{instance}', 0) for instance in instances] for method in methods}\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(table_data, index=instances)\n",
    "            dfs.append(df.copy())\n",
    "\n",
    "    \n",
    "    result_df = sum(dfs)\n",
    "    # Calculate total for each row and add as a new column\n",
    "    result_df['Total'] = result_df.sum(axis=1)\n",
    "    \n",
    "    # Calculate total for each column and append as a new row\n",
    "    result_df.loc['Total'] = result_df.sum()\n",
    "\n",
    "    # Convert to LaTeX table\n",
    "    latex_table = result_df.to_latex(index=True, float_format=\"%.2f\")\n",
    "    \n",
    "    # Print the LaTeX code\n",
    "    print(latex_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce4f6491-84a9-406e-9ecd-0d1c52571987",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 adjusted_time_increase\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & -0.71 ± 0.16 & -1.00 ± 0.00 & -0.94 ± 0.07 & -0.82 ± 0.13 & -0.81 ± 0.14 & -0.82 ± 0.14 & -0.92 ± 0.13 \\\\\n",
      "2 & -0.01 ± 0.25 & -0.98 ± 0.01 & -0.58 ± 0.14 & -0.40 ± 0.20 & -0.36 ± 0.21 & -0.38 ± 0.20 & -0.52 ± 0.25 \\\\\n",
      "3 & -0.66 ± 0.18 & -0.67 ± 0.09 & -0.84 ± 0.11 & -0.74 ± 0.17 & -0.72 ± 0.18 & -0.72 ± 0.18 & -0.73 ± 0.16 \\\\\n",
      "4 & -0.01 ± 0.26 & -0.97 ± 0.01 & -0.53 ± 0.15 & -0.23 ± 0.22 & -0.21 ± 0.23 & -0.23 ± 0.22 & -0.42 ± 0.27 \\\\\n",
      "5 & -0.66 ± 0.18 & -0.67 ± 0.09 & -0.84 ± 0.11 & -0.74 ± 0.17 & -0.72 ± 0.18 & -0.72 ± 0.18 & -0.73 ± 0.16 \\\\\n",
      "6 & 0.09 ± 0.16 &  & -0.17 ± 0.27 & 0.06 ± 0.25 & 0.06 ± 0.26 & 0.06 ± 0.25 & 0.04 ± 0.25 \\\\\n",
      "x & -0.71 ± 0.16 &  & -0.93 ± 0.08 & -0.83 ± 0.13 & -0.81 ± 0.14 & -0.82 ± 0.14 & -0.84 ± 0.14 \\\\\n",
      "Total & -0.43 ± 0.26 & -0.95 ± 0.07 & -0.79 ± 0.15 & -0.62 ± 0.21 & -0.60 ± 0.22 & -0.61 ± 0.21 & -0.51 ± 0.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "0 time_increase\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 \\\\\n",
      "2 & -0.54 ± 0.12 & -0.98 ± 0.01 & -0.78 ± 0.10 & -0.78 ± 0.11 & -0.77 ± 0.11 & -0.78 ± 0.11 & -0.82 ± 0.11 \\\\\n",
      "3 & -0.98 ± 0.01 & -0.67 ± 0.09 & -0.96 ± 0.02 & -0.97 ± 0.02 & -0.96 ± 0.02 & -0.96 ± 0.02 & -0.95 ± 0.04 \\\\\n",
      "4 & -0.54 ± 0.12 & -0.97 ± 0.01 & -0.74 ± 0.10 & -0.61 ± 0.11 & -0.62 ± 0.11 & -0.63 ± 0.11 & -0.72 ± 0.12 \\\\\n",
      "5 & -0.98 ± 0.01 & -0.67 ± 0.09 & -0.96 ± 0.02 & -0.97 ± 0.02 & -0.96 ± 0.02 & -0.96 ± 0.02 & -0.95 ± 0.04 \\\\\n",
      "6 & -0.86 ± 0.07 &  & -0.66 ± 0.11 & -0.74 ± 0.11 & -0.74 ± 0.11 & -0.74 ± 0.11 & -0.74 ± 0.11 \\\\\n",
      "x & -0.71 ± 0.16 &  & -0.93 ± 0.08 & -0.83 ± 0.13 & -0.81 ± 0.14 & -0.82 ± 0.14 & -0.84 ± 0.14 \\\\\n",
      "Total & -0.93 ± 0.12 & -0.95 ± 0.07 & -0.93 ± 0.07 & -0.93 ± 0.10 & -0.93 ± 0.10 & -0.93 ± 0.10 & -0.78 ± 0.10 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "0 optimal_gap\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & 0.72 ± 0.02 & 0.72 ± 0.01 & 0.59 ± 0.03 & 0.67 ± 0.03 & 0.66 ± 0.03 & 0.66 ± 0.03 & 0.68 ± 0.02 \\\\\n",
      "2 & 0.14 ± 0.01 & 0.40 ± 0.02 & 0.15 ± 0.01 & 0.18 ± 0.01 & 0.18 ± 0.01 & 0.18 ± 0.01 & 0.20 ± 0.02 \\\\\n",
      "3 & 0.49 ± 0.02 & 0.20 ± 0.01 & 0.30 ± 0.03 & 0.38 ± 0.03 & 0.37 ± 0.03 & 0.36 ± 0.03 & 0.35 ± 0.03 \\\\\n",
      "4 & 0.14 ± 0.01 & 0.39 ± 0.02 & 0.13 ± 0.01 & 0.12 ± 0.01 & 0.12 ± 0.01 & 0.12 ± 0.01 & 0.15 ± 0.02 \\\\\n",
      "5 & 0.49 ± 0.02 & 0.20 ± 0.01 & 0.30 ± 0.03 & 0.38 ± 0.03 & 0.37 ± 0.03 & 0.36 ± 0.03 & 0.35 ± 0.03 \\\\\n",
      "6 & 0.45 ± 0.02 &  & 0.28 ± 0.03 & 0.33 ± 0.04 & 0.33 ± 0.04 & 0.32 ± 0.04 & 0.33 ± 0.04 \\\\\n",
      "x & 0.80 ± 0.02 &  & 0.42 ± 0.04 & 0.68 ± 0.05 & 0.67 ± 0.05 & 0.67 ± 0.05 & 0.66 ± 0.06 \\\\\n",
      "Total & 0.47 ± 0.07 & 0.34 ± 0.05 & 0.28 ± 0.04 & 0.36 ± 0.06 & 0.35 ± 0.06 & 0.34 ± 0.06 & 0.38 ± 0.06 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "1 adjusted_time_increase\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & -0.01 ± 0.07 & -1.00 ± 0.00 & -0.54 ± 0.13 & -0.13 ± 0.12 & -0.09 ± 0.12 & -0.13 ± 0.12 & -0.37 ± 0.17 \\\\\n",
      "2 & 0.24 ± 0.20 & -0.97 ± 0.01 & -0.38 ± 0.19 & -0.03 ± 0.17 & -0.01 ± 0.19 & -0.03 ± 0.18 & -0.20 ± 0.30 \\\\\n",
      "3 & 0.01 ± 0.13 & -0.61 ± 0.12 & -0.32 ± 0.18 & -0.01 ± 0.23 & -0.01 ± 0.21 & -0.01 ± 0.22 & -0.08 ± 0.20 \\\\\n",
      "4 & 0.24 ± 0.20 & -0.97 ± 0.01 & -0.23 ± 0.20 & -0.01 ± 0.22 & 0.02 ± 0.22 & -0.00 ± 0.22 & -0.12 ± 0.32 \\\\\n",
      "5 & 0.01 ± 0.13 & -0.61 ± 0.12 & -0.32 ± 0.18 & -0.01 ± 0.23 & -0.01 ± 0.21 & -0.01 ± 0.22 & -0.08 ± 0.20 \\\\\n",
      "6 & 0.16 ± 0.19 &  & 0.14 ± 0.34 & 0.25 ± 0.28 & 0.18 ± 0.29 & 0.18 ± 0.29 & 0.18 ± 0.29 \\\\\n",
      "x & -0.01 ± 0.07 &  & -0.49 ± 0.13 & -0.13 ± 0.12 & -0.06 ± 0.12 & -0.14 ± 0.12 & -0.04 ± 0.12 \\\\\n",
      "Total & 0.02 ± 0.17 & -0.94 ± 0.10 & -0.30 ± 0.22 & -0.02 ± 0.22 & -0.01 ± 0.22 & -0.02 ± 0.22 & -0.51 ± 0.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "1 time_increase\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 & -1.00 ± 0.00 \\\\\n",
      "2 & -0.67 ± 0.11 & -0.97 ± 0.01 & -0.92 ± 0.05 & -0.93 ± 0.05 & -0.91 ± 0.06 & -0.91 ± 0.06 & -0.92 ± 0.07 \\\\\n",
      "3 & -0.97 ± 0.04 & -0.61 ± 0.12 & -0.95 ± 0.04 & -0.95 ± 0.06 & -0.95 ± 0.05 & -0.95 ± 0.06 & -0.94 ± 0.08 \\\\\n",
      "4 & -0.67 ± 0.11 & -0.97 ± 0.01 & -0.88 ± 0.07 & -0.85 ± 0.08 & -0.84 ± 0.07 & -0.83 ± 0.07 & -0.87 ± 0.08 \\\\\n",
      "5 & -0.97 ± 0.04 & -0.61 ± 0.12 & -0.95 ± 0.04 & -0.95 ± 0.06 & -0.95 ± 0.06 & -0.95 ± 0.06 & -0.94 ± 0.08 \\\\\n",
      "6 & -0.81 ± 0.11 &  & -0.51 ± 0.14 & -0.50 ± 0.14 & -0.53 ± 0.14 & -0.54 ± 0.14 & -0.57 ± 0.14 \\\\\n",
      "x & -0.01 ± 0.07 &  & -0.49 ± 0.13 & -0.13 ± 0.12 & -0.06 ± 0.12 & -0.14 ± 0.12 & -0.04 ± 0.12 \\\\\n",
      "Total & -0.88 ± 0.15 & -0.94 ± 0.10 & -0.90 ± 0.11 & -0.91 ± 0.12 & -0.90 ± 0.12 & -0.90 ± 0.12 & -0.78 ± 0.10 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "1 optimal_gap\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\toprule\n",
      "option & rnd & bsl & zip & min & avg & max & Total \\\\\n",
      "heuristic &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & 0.57 ± 0.02 & 0.73 ± 0.01 & 0.30 ± 0.03 & 0.39 ± 0.03 & 0.38 ± 0.03 & 0.37 ± 0.03 & 0.47 ± 0.05 \\\\\n",
      "2 & 0.13 ± 0.01 & 0.40 ± 0.02 & 0.11 ± 0.01 & 0.14 ± 0.01 & 0.13 ± 0.01 & 0.14 ± 0.01 & 0.16 ± 0.02 \\\\\n",
      "3 & 0.35 ± 0.02 & 0.19 ± 0.01 & 0.10 ± 0.02 & 0.14 ± 0.02 & 0.14 ± 0.02 & 0.14 ± 0.02 & 0.18 ± 0.03 \\\\\n",
      "4 & 0.13 ± 0.01 & 0.39 ± 0.02 & 0.09 ± 0.01 & 0.10 ± 0.01 & 0.09 ± 0.01 & 0.10 ± 0.01 & 0.12 ± 0.02 \\\\\n",
      "5 & 0.35 ± 0.02 & 0.19 ± 0.01 & 0.10 ± 0.02 & 0.14 ± 0.02 & 0.14 ± 0.02 & 0.14 ± 0.02 & 0.18 ± 0.03 \\\\\n",
      "6 & 0.37 ± 0.03 &  & 0.12 ± 0.02 & 0.14 ± 0.03 & 0.15 ± 0.03 & 0.16 ± 0.03 & 0.18 ± 0.03 \\\\\n",
      "x & 0.56 ± 0.03 &  & 0.06 ± 0.02 & 0.22 ± 0.05 & 0.21 ± 0.05 & 0.21 ± 0.05 & 0.24 ± 0.06 \\\\\n",
      "Total & 0.35 ± 0.05 & 0.35 ± 0.05 & 0.11 ± 0.02 & 0.16 ± 0.03 & 0.16 ± 0.03 & 0.16 ± 0.03 & 0.38 ± 0.06 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Mean and variance of the relative increase in total resolution time, relative increase in resolution time and relative optimal gap for transformations unconstrained by H4\n",
    "\n",
    "\n",
    "df = RESULTS['combined']['meta_data_df']\n",
    "for h4 in range(2):\n",
    "    filter_df = df[df['H4']==h4]\n",
    "    for val in ['adjusted_time_increase', 'time_increase', 'optimal_gap']:\n",
    "        print(h4, val)\n",
    "        # Group by 'strategy' and 'method', then calculate mean and variance\n",
    "        agg_df = filter_df.groupby(['heuristic', 'option'])[val].agg(['median', 'mean', 'std', 'var'])\n",
    "        \n",
    "        # Format the result as \"mean ± variance\"\n",
    "        formatted_agg_df = agg_df.apply(lambda x: f\"{x['mean']:.2f} ± {x['var']:.2f}\", axis=1)\n",
    "        \n",
    "        # Reshape to have 'heuristic' as rows and 'option' as columns\n",
    "        final_table = formatted_agg_df.unstack(level='option').fillna('')\n",
    "        \n",
    "        # Add Row Totals (mean ± variance across columns)\n",
    "        row_totals = filter_df.groupby('heuristic')[val].agg(['mean', 'var'])\n",
    "        row_totals_formatted = row_totals.apply(lambda x: f\"{x['mean']:.2f} ± {x['var']:.2f}\", axis=1)\n",
    "        final_table['Total'] = row_totals_formatted\n",
    "        \n",
    "        # Add Column Totals (mean ± variance across rows)\n",
    "        col_totals = filter_df.groupby('option')[val].agg(['mean', 'var'])\n",
    "        col_totals_formatted = col_totals.apply(lambda x: f\"{x['mean']:.2f} ± {x['var']:.2f}\", axis=1)\n",
    "        # Add an extra row for column totals at the bottom\n",
    "        final_table.loc['Total'] = col_totals_formatted\n",
    "\n",
    "        grand_total_mean = df[val].mean()\n",
    "        grand_total_var = df[val].var()\n",
    "        \n",
    "        # Format the grand total for the bottom-right element\n",
    "        grand_total_formatted = f\"{grand_total_mean:.2f} ± {grand_total_var:.2f}\"\n",
    "        \n",
    "        \n",
    "        # Assign the grand total to the bottom-right cell\n",
    "        final_table.at['Total', 'Total'] = grand_total_formatted\n",
    "\n",
    "\n",
    "        final_table = final_table[['rnd', 'bsl',  'zip', 'min', 'avg', 'max', 'Total']]\n",
    "        # Convert the final table to LaTeX format\n",
    "        latex_table = final_table.to_latex(\n",
    "            header=True,  # Include column headers\n",
    "            index=True,   # Include row indices (heuristics)\n",
    "            column_format='|c|' + 'c|' * (len(final_table.columns)-1),  # Adjust for added Total column\n",
    "            escape=False  # Allow LaTeX special characters (like ±)\n",
    "        )\n",
    "        \n",
    "        # Print or save the LaTeX table\n",
    "        print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
